{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg09bB9Okc_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c181375-a097-421a-a05f-bd8b3e54e968"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import torchtext.vocab\n",
        "import tqdm\n",
        "\n",
        "from nltk import tokenize\n",
        "\n",
        "from torchtext.legacy.data import Field, LabelField, TabularDataset, BucketIterator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M--V30gykxM1"
      },
      "source": [
        "### Carregar os arquivos do GDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HStM5qDOkhfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c23833e-1cd3-4948-d92c-1f9581d85b8e"
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9m6Is4KglAIo"
      },
      "source": [
        "### Reprodutibilidade"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGstIRzilGWD"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu7wnX0plSqZ"
      },
      "source": [
        "### Pré-processar texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3icsqsXlVcX"
      },
      "source": [
        "def tokenizer(text):\n",
        "    return tokenize.word_tokenize(text, language='portuguese')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-azOXD9ylbYF"
      },
      "source": [
        "path = \"drive/MyDrive/Colab Notebooks/nn2pln/corpus/\"\n",
        "\n",
        "def process_splits():\n",
        "    text = Field(tokenize=tokenizer)\n",
        "    label = LabelField(dtype=torch.float)\n",
        "    \n",
        "    train, valid, test = TabularDataset.splits(path=path, train='balanced_train_apps.csv',\n",
        "                                               validation='balanced_dev_apps.csv',\n",
        "                                               test='balanced_test_apps.csv', format='csv',\n",
        "                                               fields=[('text', text), ('helpfulness', label)], \n",
        "                                               skip_header=True)\n",
        "   \n",
        "    print(vars(test[0]))\n",
        "    text.build_vocab(train)\n",
        "    label.build_vocab(train)\n",
        "\n",
        "    # string -> inteiro\n",
        "    print(list(text.vocab.stoi.items())[:10])\n",
        "\n",
        "    # inteiro -> string\n",
        "    print(text.vocab.itos[:10])\n",
        "\n",
        "    return train, valid, test, text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YARH2iBRjxFu"
      },
      "source": [
        "### Criar os iteradores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgOIPkVBqXZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "077557d8-a746-4763-ebfe-3f0497e767eb"
      },
      "source": [
        "train, val, test, text = process_splits()\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# criar minibatch\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train, val, test),\n",
        "                                                                      sort_key=lambda x: len(x.text), \n",
        "                                                                      batch_size=BATCH_SIZE,\n",
        "                                                                      device=device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['App', 'ótimo', 'recomendo', '.', 'Se', 'tivesse', 'chamada', 'de', 'vedio', 'privado', 'séria', 'melhor', 'ainda', '.'], 'helpfulness': '0.0'}\n",
            "[('<unk>', 0), ('<pad>', 1), (',', 2), ('.', 3), ('e', 4), ('o', 5), ('de', 6), ('que', 7), ('a', 8), ('!', 9)]\n",
            "['<unk>', '<pad>', ',', '.', 'e', 'o', 'de', 'que', 'a', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1TATuYyj1kK"
      },
      "source": [
        "### Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMAwdZJ1j3Z8"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        \n",
        "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
        "        \n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        # text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        embedded = embedded.permute(1, 0, 2)\n",
        "        # embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        output = F.relu(self.fc1(embedded.mean(dim=1)))\n",
        "        # output = [batch size, hid dim]\n",
        "        \n",
        "        out = self.fc2(output)\n",
        "        # out = [batch size, hid out]\n",
        "        \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THLIgAh4lvjP"
      },
      "source": [
        "### Parâmetros do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1csod5grlyUQ"
      },
      "source": [
        "INPUT_DIM = len(text.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = MLP(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7xZs4iBmy9W"
      },
      "source": [
        "### Quantidade de parâmetros treináveis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxdT9AMNm2BG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba1422c2-c9b1-42ee-e46a-50c294e52308"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'O modelo tem {count_parameters(model):,} parâmetros treináveis')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O modelo tem 6,114,513 parâmetros treináveis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf8Qfe21nJlk"
      },
      "source": [
        "### Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXohINLNnLFy"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in tqdm.tqdm(iterator, desc='training...'):\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.helpfulness)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myejTkwCnRJa"
      },
      "source": [
        "### Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Jg5o7O9nSzK"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    total_predictions = []\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in tqdm.tqdm(iterator, desc='evaluating...'):\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            total_predictions.extend(p.item() for p in predictions)\n",
        "            \n",
        "            loss = criterion(predictions, batch.helpfulness)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), total_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl2mmD0tnYSJ"
      },
      "source": [
        "### Execução"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f2qgNbQnZ2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1685b1a1-375f-4f33-91ba-c723bfe29a70"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, _ = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'mlp.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 2381/2381 [00:10<00:00, 228.95it/s]\n",
            "evaluating...: 100%|██████████| 340/340 [00:00<00:00, 588.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01\n",
            "\tTrain Loss: 0.670\n",
            "\t Val. Loss: 0.707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 2381/2381 [00:09<00:00, 242.36it/s]\n",
            "evaluating...: 100%|██████████| 340/340 [00:00<00:00, 561.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 02\n",
            "\tTrain Loss: 0.651\n",
            "\t Val. Loss: 0.731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 2381/2381 [00:09<00:00, 243.41it/s]\n",
            "evaluating...: 100%|██████████| 340/340 [00:00<00:00, 564.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 03\n",
            "\tTrain Loss: 0.635\n",
            "\t Val. Loss: 0.767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 2381/2381 [00:09<00:00, 241.60it/s]\n",
            "evaluating...: 100%|██████████| 340/340 [00:00<00:00, 576.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 04\n",
            "\tTrain Loss: 0.623\n",
            "\t Val. Loss: 0.812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training...: 100%|██████████| 2381/2381 [00:09<00:00, 244.63it/s]\n",
            "evaluating...: 100%|██████████| 340/340 [00:00<00:00, 576.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 05\n",
            "\tTrain Loss: 0.612\n",
            "\t Val. Loss: 0.862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c58j-dcn5fG"
      },
      "source": [
        "### Teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi8crPwcn7Y8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9a6fd52-3357-424e-a88c-82c586557713"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "model.load_state_dict(torch.load('mlp.pt'))\n",
        "\n",
        "test_loss, predictions = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f}')\n",
        "\n",
        "preds = torch.FloatTensor(predictions)\n",
        "rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "  \n",
        "labels = [float(t.helpfulness) for t in test]\n",
        "print(classification_report(labels, rounded_preds.detach().numpy()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "evaluating...: 100%|██████████| 681/681 [00:01<00:00, 537.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.706\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.72      0.00      0.01     10882\n",
            "         1.0       0.50      1.00      0.67     10882\n",
            "\n",
            "    accuracy                           0.50     21764\n",
            "   macro avg       0.61      0.50      0.34     21764\n",
            "weighted avg       0.61      0.50      0.34     21764\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al4dNcB3I0RL"
      },
      "source": [
        "### Predição"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ3pJbZsIzoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f2085c-b4ee-4a05-eef0-c063d3cc2fde"
      },
      "source": [
        "def predict(sentence):\n",
        "    model.eval()\n",
        "    tokenized = tokenizer(sentence)\n",
        "    \n",
        "    # token -> int\n",
        "    indexed = [text.vocab.stoi[t] for t in tokenized]\n",
        "\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "\n",
        "    prediction = torch.sigmoid(model(tensor))\n",
        "    return prediction.item()\n",
        "\n",
        "print(predict('O celular é muito bom, a câmera é muito boa.'))\n",
        "print(predict('A câmera é péssima.'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5807092189788818\n",
            "0.6065695285797119\n"
          ]
        }
      ]
    }
  ]
}